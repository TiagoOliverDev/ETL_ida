# ETL IDA - Pipeline de Dados do √çndice de Desempenho no Atendimento

[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Airflow DAG](https://img.shields.io/badge/Airflow-DAG-blue)](http://localhost:8080)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-‚úîÔ∏è-blue)](https://www.postgresql.org/)


Pipeline ETL para extra√ß√£o, transforma√ß√£o e carga dos dados do √çndice de Desempenho no Atendimento (IDA) das operadoras de telecomunica√ß√µes, usando Python, Apache Airflow e PostgreSQL.

---

## üìö Vis√£o Geral

- **Extra√ß√£o: Dados extra√≠dos de arquivos ODS com informa√ß√µes de IDA.**
- **Transforma√ß√£o: Normaliza√ß√£o, limpeza e tratamento dos dados com Pandas.** 
- **Carga: Inser√ß√£o dos dados transformados em um banco PostgreSQL estruturado com modelo estrela (fato + dimens√µes).** 
- **Orquestra√ß√£o: Apache Airflow gerencia a execu√ß√£o di√°ria do pipeline via DAG.** 

---

## üóÇÔ∏è Estrutura do Projeto

```bash
ETL_ida/                                              # Raiz do projeto ETL para IDA
‚îú‚îÄ‚îÄ config/                                           # Configura√ß√µes globais do projeto
‚îÇ   ‚îî‚îÄ‚îÄ settings.py                                   # Par√¢metros, paths e vari√°veis fixas
‚îú‚îÄ‚îÄ dags/                                             # DAGs do Airflow (pipelines)
‚îÇ     ‚îî‚îÄ‚îÄ etl_ida_dag.py                              # Defini√ß√£o da DAG principal de ETL
‚îú‚îÄ‚îÄ data/                                             # Diret√≥rios para dados
‚îÇ   ‚îú‚îÄ‚îÄ raw/                                          # Dados brutos coletados (ODS, CSV, etc)
‚îÇ   ‚îî‚îÄ‚îÄ processed/                                    # Dados transformados prontos para carga/an√°lise
‚îú‚îÄ‚îÄ logs/                                             # Logs gerados em execu√ß√£o para auditoria/debug
‚îú‚îÄ‚îÄ plugins/                                          # Plugins e extens√µes personalizadas do Airflow
‚îú‚îÄ‚îÄ src/                                              # C√≥digo fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ db/                                           # M√≥dulo de banco de dados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repositories/                             # Reposit√≥rios para acesso e manipula√ß√£o das tabelas
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ base.py                               # Classe base de reposit√≥rio gen√©rico
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ dim_grupo_economico.py                # Reposit√≥rio da dimens√£o grupo econ√¥mico
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ dim_servico.py                        # Reposit√≥rio da dimens√£o servi√ßo
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ dim_tempo.py                          # Reposit√≥rio da dimens√£o tempo
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ dim_variavel.py                       # Reposit√≥rio da dimens√£o vari√°vel
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ fato_ida.py                           # Reposit√≥rio da tabela fato
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sql/                                      # Scripts SQL brutos
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ create_tables.sql                     # Script de cria√ß√£o das tabelas no banco
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ create_tables.py                          # Script Python para cria√ß√£o das tabelas via SQLAlchemy (opcional)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py                               # Configura√ß√£o de conex√£o e engine do banco
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.py                                 # Modelos ORM (SQLAlchemy) das tabelas
‚îÇ   ‚îú‚îÄ‚îÄ etl/                                          # Pipeline ETL principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract.py                                # C√≥digo para extrair dados da fonte
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ load.py                                   # C√≥digo para carregar dados no banco
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transform.py                              # C√≥digo para transformar e limpar os dados
‚îÇ   ‚îú‚îÄ‚îÄ utils/                                        # Utilit√°rios gerais
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.py                                 # Configura√ß√£o e inicializa√ß√£o do logger
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py                                  # Fun√ß√µes utilit√°rias variadas
‚îÇ   ‚îî‚îÄ‚îÄ main.py                                       # Script principal para executar o ETL localmente (batch)
‚îú‚îÄ‚îÄ tests/                                            # Testes automatizados do projeto
‚îú‚îÄ‚îÄ .env.example                                      # Exemplo de arquivo de vari√°veis ambiente para configurar o projeto
‚îú‚îÄ‚îÄ .gitignore                                        # Arquivos e pastas ignorados pelo git
‚îú‚îÄ‚îÄ .dockerignore                                     # Arquivos e pastas ignorados na constru√ß√£o da imagem Docker
‚îú‚îÄ‚îÄ Dockerfile-airflow                                # Dockerfile customizado para o container Airflow
‚îú‚îÄ‚îÄ docker-compose.yml                                # Orquestra√ß√£o Docker (Airflow, bancos, ETL, etc)
‚îú‚îÄ‚îÄ Dockerfile                                        # Dockerfile base para o ETL (Python, depend√™ncias)
‚îú‚îÄ‚îÄ requirements.txt                                  # Depend√™ncias Python do projeto
‚îî‚îÄ‚îÄ main_local.py                                     # Script alternativo para execu√ß√£o local do ETL
‚îî‚îÄ‚îÄ wait-for-postgres.sh                              # Script shell para aguardar o banco estar pronto no container
```

---

## ‚öôÔ∏è Arquitetura do Processamento de dados

```bash
+----------------+        +---------------------+        +------------------+
| Dados ODS (raw)| -----> | Processamento ETL    | -----> | PostgreSQL (data) |
| (Extrair,      |        | (Transform + Load)  |        | (Modelo Estrela)  |
| Transformar)   |        | via Airflow DAG     |        +------------------+
+----------------+        +---------------------+

```

---

## ‚öôÔ∏è Configura√ß√£o do Ambiente

### 1. **Pr√©-requisitos**

- [Docker](https://www.docker.com/)
- [Docker Compose](https://docs.docker.com/compose/)
- Python 3.11+ (para execu√ß√µes locais e testes)

---

### 2. **Clone o Reposit√≥rio**

```bash
git clone https://github.com/TiagoOliverDev/ETL_ida
cd ETL_ida
```

---

### 3. **Crie o Arquivo `.env`**

Baseie-se no modelo `.env.example`.

---

### 4. **Suba o Ambiente com Docker Compose e aguarde alguns minutos at√© que tudo seja buildado**

```bash
docker-compose up --build
```

- Airflow: [http://localhost:8080](http://localhost:8080)

---

### 5. **Ative a DAG no Airflow**

1. Acesse a interface web do Airflow: [http://localhost:8080](http://localhost:8080)
2. Loge com as cred√™nciais username=admin e senha=admin
2. Ative a DAG `etl_ida_dag.py`
3. No canto superior passe o mouse no menu "Admin", clique em "Connections", clique no "+ em azul", no campo "Connection_id" digite "local_postgres_conn", em "Connection type selecione "Postgres" e insira as cred√™nciais abaixo e clique em save e volte para a home"

```
DB_USER=etl_user
DB_PASSWORD=etl_pass
DB_HOST=etl-db 
DB_PORT=5432 
DB_NAME=etl_db

```

4. Feito os passos anteriores e clicando na chave ao lado esquerdo da dag ida_etl v√° em "Actions" e clique em Trigger Dag (simbolo de seta pra direita e aguarde o processo rodar e ficar em verde)

5. Ap√≥s processo finalizado e projeto rodando via docker voc√™ poderar acessar o banco localhost via dbeaver e consultar os dados nas tabelas e na view vw_taxa_variacao_ida

---

## üõ†Ô∏è Execu√ß√£o Manual (fora do Airflow)

```bash
python main_local.py
```

---


## üìù Observa√ß√µes

- O projeto inteiro  roda via docker-compose mas tamb√©m √© poss√≠vel rodar local (python main_local.py) ap√≥s buildar as imagens 

---

## üìö Licen√ßa

Este projeto √© open-source e est√° sob a licen√ßa [MIT](LICENSE).

---

## üë®‚Äçüíª Desenvolvido por

**Tiago Oliveira**  
Analista desenvolvedor e Engenheiro de dados em forma√ß√£o

- üíº [LinkedIn](https://www.linkedin.com/in/tiago-oliveira-49a2a6205/)
- üíª [GitHub](https://github.com/TiagoOliverDev)